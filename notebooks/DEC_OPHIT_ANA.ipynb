{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deconvolution of the LArSoft opdet simulation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is used to analyse wvfs of the deconvolution module in larsoft. The output of the workflow is a collection of hits. The hits are then converted into a format that can be compared against the true photon information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The wvfs are loaded. For a full comparison, the current \"IDEAL\" template is compared agains the \"RAW\" wvf generated from the arapuca temnplate and the \"DEC\" wvf generated from the deconvolution module (using both \"GAUSS\" and \"WIENER\" filters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.insert(0, '../'); from lib.__init__ import *\n",
    "# Load data according to type: RAW (digitized), DEC (deconvolved)\n",
    "max_ev = 20\n",
    "%time data0 = load_root_new(\"RAW\",\"../data/DAPHNE_FBK/opdetraw_ideal_hist.root\",    [\"opdigi\",\"opdigiana\"],np.loadtxt(\"../template/MILANO/FBK/DAPHNE2_FBK_2022.txt\"),max_ev=max_ev,label=\"IDEAL\")\n",
    "%time data1 = load_root_new(\"RAW\",\"../data/DAPHNE_FBK/opdetraw_template_hist.root\", [\"opdigi\",\"opdigiana\"],np.loadtxt(\"../template/MILANO/FBK/DAPHNE2_FBK_2022.txt\"),max_ev=max_ev,label=\"RAW\")\n",
    "%time data2 = load_root_new(\"DEC\",\"../data/DAPHNE_FBK/deconv_gauss_hist.root\",      [\"opdigi\",\"opdecoana\"],np.loadtxt(\"../template/MILANO/FBK/DAPHNE2_FBK_2022.txt\"),max_ev=max_ev,label=\"GAUSS\")\n",
    "%time data3 = load_root_new(\"DEC\",\"../data/DAPHNE_FBK/deconv_wiener_hist.root\",     [\"opdigi\",\"opdecoana\"],np.loadtxt(\"../template/MILANO/FBK/DAPHNE2_FBK_2022.txt\"),max_ev=max_ev,label=\"WIENER\")\n",
    "\n",
    "# Select your favorite color map\n",
    "color_map={data0[\"LABEL\"]:\"violet\", \n",
    "           data1[\"LABEL\"]:\"#3366CC\", \n",
    "           data2[\"LABEL\"]:\"#66AA00\", \n",
    "           data3[\"LABEL\"]:\"#FF9900\"\n",
    "           }\n",
    "# sandybrown,seagreen,seashell,sienna,silver,skyblue,slateblue,slategray,slategrey,snow,springgreen,steelblue,tan,teal,thistle,tomato,turquoise,violet,wheat,white,whitesmoke,yellow,yellowgreen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The ophit data is loaded separetly. The ophit data is then converted into a format that can be compared against the true photons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ophit data for each type\n",
    "branches = [\"Amplitude\",\"EventID\",\"OpChannel\",\"PE\",\"PeakTime\",\"Width\"]\n",
    "%time raw_reco0 = ophit_data(\"../data/DAPHNE_FBK/ophitspe_ideal_hist.root\", scaling=1,label=\"IDEAL\",   branches=branches,as_df=False)\n",
    "%time raw_reco1 = ophit_data(\"../data/DAPHNE_FBK/ophitspe_raw_hist.root\",   scaling=1,label=\"RAW\",     branches=branches,as_df=False)\n",
    "%time raw_reco2 = ophit_data(\"../data/DAPHNE_FBK/ophitspe_gauss_hist.root\", scaling=300,label=\"GAUSS\", branches=branches,as_df=False)\n",
    "%time raw_reco3 = ophit_data(\"../data/DAPHNE_FBK/ophitspe_wiener_hist.root\",scaling=100,label=\"WIENER\",branches=branches,as_df=False)\n",
    "\n",
    "%time reco0 = order_ophit_data(raw_reco0,max_ev,data0[\"RECO\"][\"CH\"])\n",
    "%time reco1 = order_ophit_data(raw_reco1,max_ev,data1[\"RECO\"][\"CH\"])\n",
    "%time reco2 = order_ophit_data(raw_reco2,max_ev,data2[\"RECO\"][\"CH\"])\n",
    "%time reco3 = order_ophit_data(raw_reco3,max_ev,data3[\"RECO\"][\"CH\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Finally, the hits are compared against the true photons and exported to the same format as the wvf data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine data and ophit data\n",
    "%time ophit0 = combine_data_ophit(data0,reco0)\n",
    "%time ophit1 = combine_data_ophit(data1,reco1)\n",
    "%time ophit2 = combine_data_ophit(data2,reco2)\n",
    "%time ophit3 = combine_data_ophit(data3,reco3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize individual wvfs according to event, channel and wvf number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between a random channel number or select yourself\n",
    "# ev = 1; ch = 389; wf = 0\n",
    "ev = np.random.choice(data1[\"RECO\"][\"EV\"])\n",
    "ch = np.random.choice(data1[\"RECO\"][\"CH\"][data1[\"RECO\"][\"EV\"] == ev])\n",
    "wf = np.random.choice(data1[\"RECO\"][\"#WVF\"][(data1[\"RECO\"][\"EV\"] == ev)*(data1[\"RECO\"][\"CH\"] == ch)])\n",
    "\n",
    "# Find the index of the channel number in the data\n",
    "try:\n",
    "    num0 = np.where((data0[\"RECO\"][\"EV\"] == ev)*(data0[\"RECO\"][\"CH\"] == ch)*(data0[\"RECO\"][\"#WVF\"] == wf))[0][0]\n",
    "except:\n",
    "    num0 = 0\n",
    "    print(\"No ideal data for %s %s %s\"%(ev,ch,wf))\n",
    "    \n",
    "num1 = np.where((data1[\"RECO\"][\"EV\"] == ev)*(data1[\"RECO\"][\"CH\"] == ch)*(data1[\"RECO\"][\"#WVF\"] == wf))[0][0]\n",
    "\n",
    "# Genarte figure with subplots\n",
    "fig = make_subplots(rows=2, cols=2,subplot_titles=('', ''))\n",
    "\n",
    "# Add waveform traces to the figure\n",
    "fig.add_trace(go.Scatter(line=dict(color=color_map[data0[\"LABEL\"]]),name=\"%s #PE: %.2f\"%(data0[\"LABEL\"],data0[\"RECO\"][\"PE\"][num0]),x=1e6*16e-9*(np.linspace(0,1000,1001))+data0[\"RECO\"][\"WVF_IX\"][num0],y=data0[\"RECO\"][\"WVF\"][num0]-data0[\"PEDESTAL\"]),col=1,row=1)\n",
    "fig.add_trace(go.Scatter(line=dict(color=color_map[data1[\"LABEL\"]]),name=\"%s #PE: %.2f\"%(data1[\"LABEL\"],data1[\"RECO\"][\"PE\"][num1]),x=1e6*16e-9*(np.linspace(0,1000,1001))+data1[\"RECO\"][\"WVF_IX\"][num1],y=data1[\"RECO\"][\"WVF\"][num1]-data1[\"PEDESTAL\"]),col=2,row=1)\n",
    "fig.add_trace(go.Scatter(line=dict(color=color_map[data2[\"LABEL\"]]),name=\"%s #PE: %.2f\"%(data2[\"LABEL\"],data2[\"RECO\"][\"PE\"][num1]),x=1e6*16e-9*(np.linspace(0,1000,1001))+data2[\"RECO\"][\"WVF_IX\"][num1],y=data2[\"RECO\"][\"WVF\"][num1]),col=1,row=2)\n",
    "fig.add_trace(go.Scatter(line=dict(color=color_map[data3[\"LABEL\"]]),name=\"%s #PE: %.2f\"%(data3[\"LABEL\"],data3[\"RECO\"][\"PE\"][num1]),x=1e6*16e-9*(np.linspace(0,1000,1001))+data3[\"RECO\"][\"WVF_IX\"][num1],y=data3[\"RECO\"][\"WVF\"][num1]),col=2,row=2)\n",
    "\n",
    "# Add vertical lines according to the reconstructed T0\n",
    "fig.add_vline(x=data0[\"RECO\"][\"T0\"][num0], line_width=2, line_dash=\"dash\", line_color=\"gray\",col=1,row=1)\n",
    "fig.add_vline(x=data1[\"RECO\"][\"T0\"][num1], line_width=2, line_dash=\"dash\", line_color=\"gray\",col=2,row=1)\n",
    "fig.add_vline(x=data2[\"RECO\"][\"T0\"][num1], line_width=2, line_dash=\"dash\", line_color=\"gray\",col=1,row=2)\n",
    "fig.add_vline(x=data3[\"RECO\"][\"T0\"][num1], line_width=2, line_dash=\"dash\", line_color=\"gray\",col=2,row=2)\n",
    "\n",
    "# Add true PE times to the figure\n",
    "# if len(data0[\"TRUE\"][\"PETIMES\"][num0]) > 100:\n",
    "# fig.add_trace(go.Histogram(name=\"TRUE #PE: %.2f\"%(len(data0[\"TRUE\"][\"PETIMES\"][num0])),x=np.asarray(data0[\"TRUE\"][\"PETIMES\"][num0])),col=1,row=1)\n",
    "# fig.add_trace(go.Histogram(name=\"TRUE #PE: %.2f\"%(len(data1[\"TRUE\"][\"PETIMES\"][num1])),x=np.asarray(data1[\"TRUE\"][\"PETIMES\"][num1])),col=2,row=1)\n",
    "# else:\n",
    "fig.add_trace(go.Scatter(marker_symbol=\"triangle-up\",mode=\"markers\",line=dict(color=\"black\"),name=\"TRUE #PE: %.2f\"%(len(data0[\"TRUE\"][\"PETIMES\"][num0])),x=np.asarray(data0[\"TRUE\"][\"PETIMES\"][num0]),y=np.zeros(len(data0[\"TRUE\"][\"PETIMES\"][num0]))),col=1,row=1)\n",
    "fig.add_trace(go.Scatter(marker_symbol=\"triangle-up\",mode=\"markers\",line=dict(color=\"black\"),name=\"TRUE #PE: %.2f\"%(len(data1[\"TRUE\"][\"PETIMES\"][num1])),x=np.asarray(data1[\"TRUE\"][\"PETIMES\"][num1]),y=np.zeros(len(data1[\"TRUE\"][\"PETIMES\"][num1]))),col=2,row=1)\n",
    "fig.add_trace(go.Scatter(marker_symbol=\"triangle-up\",mode=\"markers\",line=dict(color=\"black\"),name=\"TRUE #PE: %.2f\"%(len(data1[\"TRUE\"][\"PETIMES\"][num1])),x=np.asarray(data1[\"TRUE\"][\"PETIMES\"][num1]),y=np.zeros(len(data1[\"TRUE\"][\"PETIMES\"][num1]))),col=1,row=2)\n",
    "fig.add_trace(go.Scatter(marker_symbol=\"triangle-up\",mode=\"markers\",line=dict(color=\"black\"),name=\"TRUE #PE: %.2f\"%(len(data1[\"TRUE\"][\"PETIMES\"][num1])),x=np.asarray(data1[\"TRUE\"][\"PETIMES\"][num1]),y=np.zeros(len(data1[\"TRUE\"][\"PETIMES\"][num1]))),col=2,row=2)\n",
    "\n",
    "# Add ophits to the figure\n",
    "fig.add_trace(go.Scatter(name=\"OPHITFINDER #PE: %.2f\"%(ophit0[\"PE\"][num0]),marker=dict(color=\"#DC3912\"),mode=\"markers\",x=ophit0[\"TIMES\"][num0],y=ophit0[\"AMP\"][num0]/reco0[\"SCALING\"],error_x=dict(arrayminus=np.zeros(len(ophit0[\"WIDTH\"][num0])),array=ophit0[\"WIDTH\"][num0])),col=1,row=1)\n",
    "fig.add_trace(go.Scatter(name=\"OPHITFINDER #PE: %.2f\"%(ophit1[\"PE\"][num1]),marker=dict(color=\"#DC3912\"),mode=\"markers\",x=ophit1[\"TIMES\"][num1],y=ophit1[\"AMP\"][num1]/reco1[\"SCALING\"],error_x=dict(arrayminus=np.zeros(len(ophit1[\"WIDTH\"][num1])),array=ophit1[\"WIDTH\"][num1])),col=2,row=1)\n",
    "fig.add_trace(go.Scatter(name=\"OPHITFINDER #PE: %.2f\"%(ophit2[\"PE\"][num1]),marker=dict(color=\"#DC3912\"),mode=\"markers\",x=ophit2[\"TIMES\"][num1],y=ophit2[\"AMP\"][num1]/reco2[\"SCALING\"],error_x=dict(arrayminus=np.zeros(len(ophit2[\"WIDTH\"][num1])),array=ophit2[\"WIDTH\"][num1])),col=1,row=2)\n",
    "fig.add_trace(go.Scatter(name=\"OPHITFINDER #PE: %.2f\"%(ophit3[\"PE\"][num1]),marker=dict(color=\"#DC3912\"),mode=\"markers\",x=ophit3[\"TIMES\"][num1],y=ophit3[\"AMP\"][num1]/reco3[\"SCALING\"],error_x=dict(arrayminus=np.zeros(len(ophit3[\"WIDTH\"][num1])),array=ophit3[\"WIDTH\"][num1])),col=2,row=2)\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(title=\"Comparison for ev %i, ch %i and wvf %i\"%(ev,ch,wf),xaxis_title=\"Time in [&mu;s]\",yaxis_title=\"Amp. in [ADC]\",xaxis2_title=\"Time in [&mu;s]\",yaxis2_title=\"Amp. in [ADC]\",xaxis3_title=\"Time in [&mu;s]\",yaxis3_title=\"Amp. in [a.u.]\",xaxis4_title=\"Time in [&mu;s]\",yaxis4_title=\"Amp. in [a.u.]\")\n",
    "fig.update_layout(autosize=True,height=600,font=dict(size=16))\n",
    "# fig.update_layout(template=\"presentation\")\n",
    "# fig.update_yaxes(type=\"log\")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate further variables and formar data to generate a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_corr = 1.6284\n",
    "corrt_raw_pe = raw_corr*np.asarray(ophit1[\"PE\"])\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "    pe_error_0 = (np.asarray(data0[\"RECO\"][\"PE\"])-np.asarray(data0[\"TRUE\"][\"PE\"]))/np.asarray(data0[\"TRUE\"][\"PE\"])\n",
    "    pe_error_1 = (np.asarray(data1[\"RECO\"][\"PE\"])-np.asarray(data1[\"TRUE\"][\"PE\"]))/np.asarray(data1[\"TRUE\"][\"PE\"])\n",
    "    pe_error_2 = (np.asarray(data2[\"RECO\"][\"PE\"])-np.asarray(data1[\"TRUE\"][\"PE\"]))/np.asarray(data1[\"TRUE\"][\"PE\"])\n",
    "    pe_error_3 = (np.asarray(data3[\"RECO\"][\"PE\"])-np.asarray(data1[\"TRUE\"][\"PE\"]))/np.asarray(data1[\"TRUE\"][\"PE\"])\n",
    "    ophitpe_error_0 = (np.asarray(ophit0[\"PE\"])-np.asarray(data0[\"TRUE\"][\"PE\"]))/np.asarray(data0[\"TRUE\"][\"PE\"])\n",
    "    ophitpe_error_1 = (np.asarray(corrt_raw_pe)-np.asarray(data1[\"TRUE\"][\"PE\"]))/np.asarray(data1[\"TRUE\"][\"PE\"])\n",
    "    ophitpe_error_2 = (np.asarray(ophit2[\"PE\"])-np.asarray(data1[\"TRUE\"][\"PE\"]))/np.asarray(data1[\"TRUE\"][\"PE\"])\n",
    "    ophitpe_error_3 = (np.asarray(ophit3[\"PE\"])-np.asarray(data1[\"TRUE\"][\"PE\"]))/np.asarray(data1[\"TRUE\"][\"PE\"])\n",
    "\n",
    "    ophit_num_0 = []\n",
    "    ophit_num_1 = []\n",
    "    ophit_num_2 = []\n",
    "    ophit_num_3 = []\n",
    "    for i in range(len(pe_error_0)):\n",
    "        ophit_num_0.append(ophit0[\"TIMES\"][i].size)\n",
    "    for i in range(len(pe_error_1)):\n",
    "        ophit_num_1.append(ophit1[\"TIMES\"][i].size)\n",
    "    for i in range(len(pe_error_2)):\n",
    "        ophit_num_2.append(ophit2[\"TIMES\"][i].size)\n",
    "    for i in range(len(pe_error_3)):\n",
    "        ophit_num_3.append(ophit3[\"TIMES\"][i].size)\n",
    "\n",
    "    t0_reco_0 = np.asarray(data0[\"RECO\"][\"T0\"])-np.asarray(data0[\"TRUE\"][\"T0\"])\n",
    "    t0_reco_1 = np.asarray(data1[\"RECO\"][\"T0\"])-np.asarray(data1[\"TRUE\"][\"T0\"])\n",
    "    t0_reco_2 = np.asarray(data2[\"RECO\"][\"T0\"])-np.asarray(data1[\"TRUE\"][\"T0\"])\n",
    "    t0_reco_3 = np.asarray(data3[\"RECO\"][\"T0\"])-np.asarray(data1[\"TRUE\"][\"T0\"])\n",
    "\n",
    "    ev            = np.concatenate([data0[\"RECO\"][\"EV\"],  data1[\"RECO\"][\"EV\"],  data2[\"RECO\"][\"EV\"],  data3[\"RECO\"][\"EV\"]])\n",
    "    ch            = np.concatenate([data0[\"RECO\"][\"CH\"],  data1[\"RECO\"][\"CH\"],  data2[\"RECO\"][\"CH\"],  data3[\"RECO\"][\"CH\"]])\n",
    "    wvf           = np.concatenate([data0[\"RECO\"][\"#WVF\"],data1[\"RECO\"][\"#WVF\"],data2[\"RECO\"][\"#WVF\"],data3[\"RECO\"][\"#WVF\"]])\n",
    "    amp           = np.concatenate([data0[\"RECO\"][\"AMP\"], data1[\"RECO\"][\"AMP\"], data2[\"RECO\"][\"AMP\"], data3[\"RECO\"][\"AMP\"]])\n",
    "    pe_reco       = np.concatenate([data0[\"RECO\"][\"PE\"],  data1[\"RECO\"][\"PE\"],  data2[\"RECO\"][\"PE\"],  data3[\"RECO\"][\"PE\"]])\n",
    "    pe_true       = np.concatenate([data0[\"TRUE\"][\"PE\"],  data1[\"TRUE\"][\"PE\"],  data1[\"TRUE\"][\"PE\"],  data1[\"TRUE\"][\"PE\"]])\n",
    "    pe_ophit      = np.concatenate([ophit0[\"PE\"],         corrt_raw_pe,         ophit2[\"PE\"],         ophit3[\"PE\"]])\n",
    "    ophit_num     = np.concatenate([ophit_num_0,          ophit_num_1,          ophit_num_2,          ophit_num_3])\n",
    "    ophitpe_error = np.concatenate([ophitpe_error_0,      ophitpe_error_1,      ophitpe_error_2,      ophitpe_error_3])\n",
    "    pe_error      = np.concatenate([pe_error_0,           pe_error_1,           pe_error_2,           pe_error_3])\n",
    "    t0_reco       = np.concatenate([t0_reco_0,            t0_reco_1,            t0_reco_2,            t0_reco_3])\n",
    "    filter_label  = np.concatenate([[data0[\"LABEL\"]]*len(pe_error_0),[data1[\"LABEL\"]]*len(pe_error_1),[data2[\"LABEL\"]]*len(pe_error_2),[data3[\"LABEL\"]]*len(pe_error_3)])\n",
    "\n",
    "    df = pd.DataFrame({ \"EV\":ev,\n",
    "                        \"CH\":ch,\n",
    "                        \"WVF\":wvf,\n",
    "                        \"FILTER\":filter_label,\n",
    "                        \"ERROR PE\":pe_error,\n",
    "                        \"ERROR OPHIT PE\":ophitpe_error,\n",
    "                        \"TRUE PE\":pe_true,\n",
    "                        \"RECO PE\":pe_reco, \n",
    "                        \"OPHIT PE\":pe_ophit,\n",
    "                        \"OPHIT NUM\":ophit_num,\n",
    "                        \"AMP\":amp,\n",
    "                        \"RECO T0\":t0_reco})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gauss fit to histogram. This can be used to calculate the SPE resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_pe = 5; max_pe = 15\n",
    "this_df = df[(df[\"TRUE PE\"] > min_pe)*(df[\"TRUE PE\"] < max_pe)*(df[\"OPHIT PE\"] > 0)]\n",
    "variable = \"ERROR OPHIT PE\"\n",
    "xlim=(1,99)\n",
    "data = []\n",
    "acc = 50\n",
    "fig,data = gauss_fit_distribution(this_df,this_bin=5,variable=variable,color=\"FILTER\",color_map=color_map,output_data=data,xlim=xlim,acc=20,terminal=True)\n",
    "fig.update_layout(bargap = 0,)\n",
    "fig.update_layout(title=\"RECO PE ERROR (%i - %i TRUE PE)\"%(min_pe,max_pe),xaxis_title=\"PE ERROR [(RECO PE - TRUE PE)/TRUE PE]\",yaxis_title=\"NORM\",height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_min = 2; pe_max = 100\n",
    "variable = \"ERROR OPHIT PE\"\n",
    "pe_bins = np.arange(pe_min,pe_max,2)\n",
    "pe_bin_centers = (pe_bins[1:] + pe_bins[:-1])/2\n",
    "dict_list = []\n",
    "for idx,pe_bin in enumerate(pe_bin_centers):\n",
    "    for jdx,filter_label in enumerate([\"IDEAL\",\"RAW\",\"GAUSS\",\"WIENER\"]):\n",
    "        this_df = df[(df[\"TRUE PE\"] > pe_bins[idx])*(df[\"TRUE PE\"] < pe_bins[idx+1])*(df[\"OPHIT PE\"] > 0)*(df[\"FILTER\"] == filter_label)]\n",
    "        this_dict = {\"PE\":pe_bin,\n",
    "                    \"FILTER\":filter_label,\n",
    "                    \"MEAN '%'\":100*np.mean(this_df[variable]),\n",
    "                    \"STD '%'\":100*np.std(this_df[variable])/np.sqrt(pe_bin)}\n",
    "        dict_list.append(this_dict)\n",
    "std_df = pd.DataFrame(dict_list)\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2,subplot_titles=(\"MEAN RESIDUAL (%i-%i PE)\"%(pe_min,pe_max),\"STD RESIDUAL (%i-%i PE)\"%(pe_min,pe_max)))\n",
    "for i in range(4):\n",
    "    fig.add_trace(px.line(data_frame=std_df,\n",
    "                x=\"PE\",\n",
    "                y=\"MEAN '%'\",title=\"MEAN RESIDUAL (%i-%i PE)\"%(pe_min,pe_max), \n",
    "                # error_y=\"STD '%'\",\n",
    "                color=\"FILTER\",\n",
    "                color_discrete_map=color_map,\n",
    "                ).data[i],row=1,col=1)\n",
    "    fig.add_trace(px.line(data_frame=std_df,\n",
    "                x=\"PE\",\n",
    "                y=\"STD '%'\",title=\"STD RESIDUAL (%i-%i PE)\"%(pe_min,pe_max),log_y=True,\n",
    "                color=\"FILTER\",\n",
    "                color_discrete_map=color_map,\n",
    "                ).data[i],row=1,col=2)\n",
    "\n",
    "fig = format_coustom_plotly(fig,tickformat=(\",.2s\",\",.2s\"),figsize=(None,600),fontsize=18)\n",
    "fig.update_layout(xaxis1_title=\"TRUE PE\",yaxis1_title=\"MEAN RESIDUAL (%)\",height=600)\n",
    "fig.update_layout(xaxis2_title=\"TRUE PE\",yaxis2_title=\"STD RESIDUAL (%)\",height=600)\n",
    "# fig.update_yaxes(tickformat=\",.0f\") # use thousand comma; round to whole number\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_df = df[(df[\"TRUE PE\"] > 0) & (df[\"TRUE PE\"] < 5) & (df[\"OPHIT NUM\"] < 5) & (df[\"OPHIT NUM\"] != 0)]\n",
    "fig = px.histogram(data_frame=this_df,\n",
    "                x=\"OPHIT PE\",\n",
    "                facet_col=\"FILTER\",\n",
    "                color=\"FILTER\",\n",
    "                color_discrete_map=color_map,\n",
    "                histnorm='percent',\n",
    "                nbins=20,\n",
    "                )\n",
    "fig = format_coustom_plotly(fig,tickformat=(\",.0s\",\".0s\"),log=(False,True),figsize=(None,600),fontsize=20,facet_titles=[\"IDEAL\",\"RAW\",\"GAUSS\",\"WIENER\"])\n",
    "fig.update_yaxes(showgrid=True) # use thousand comma; round to whole number\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This shows a regular histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0_df = df[(df['TRUE PE'] > 20)*(df['TRUE PE'] < 200)]\n",
    "fig = px.histogram(data_frame=t0_df,\n",
    "                    x=\"RECO T0\",\n",
    "                    color='FILTER',\n",
    "                    color_discrete_map=color_map,\n",
    "                    barmode=\"overlay\",\n",
    "                    # marginal='box',\n",
    "                    nbins=5000,\n",
    "                    histnorm=\"percent\",\n",
    "                    )\n",
    "for i,ind in enumerate(t0_df[\"FILTER\"].unique()):\n",
    "    this_df = t0_df[t0_df[\"FILTER\"] == ind]\n",
    "    mode = this_df[\"RECO T0\"].mode().values\n",
    "    fig.add_vline(x=mode[0],line_width=3,line_dash=\"dash\",line_color=color_map[ind],annotation={\"yshift\":-i*20,\"text\":\"MODE: %.3f\"%mode[0],\"showarrow\":False})\n",
    "\n",
    "fig = format_coustom_plotly(fig,tickformat=(\",.2f\",\".2f\"),figsize=(None,600),fontsize=18,ranges=([-0.16,0.48],None))\n",
    "fig.update_layout(bargap=0,title=\"T0 RECOVERY\",xaxis_title=\"Peak Time - True PE Time [us]\",autosize=True,height=800)\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally a scintillation fit of the deconvolved wvfs is shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_wvf_length = 1000\n",
    "ave_wvfs = []\n",
    "for data in [data2,data3]:\n",
    "\n",
    "    # Select only the waveforms with a minimum length\n",
    "    data[\"RECO\"][\"SHORT_WVF\"] = []\n",
    "    for wvf in data[\"RECO\"][\"WVF\"]:\n",
    "        if len(wvf) >= min_wvf_length:\n",
    "            data[\"RECO\"][\"SHORT_WVF\"].append(wvf[:min_wvf_length])\n",
    "    print(\"Number of waveforms with length > %i: %i\"%(min_wvf_length,len(data[\"RECO\"][\"SHORT_WVF\"])))\n",
    "    # Prepare the averaged deconvolved waveforms for the scintillation profile fit\n",
    "    ave_wvf = np.mean(np.asarray(data[\"RECO\"][\"SHORT_WVF\"]),axis=0)\n",
    "    ave_wvf = ave_wvf/np.max(ave_wvf)\n",
    "    ave_wvf = ave_wvf[np.argmax(ave_wvf):np.argmax(ave_wvf)+500]\n",
    "\n",
    "    ave_wvfs.append(ave_wvf)\n",
    "    print(len(ave_wvf))\n",
    "    # Fit the scintillation profile of the averaged deconvolved waveforms\n",
    "    initial = [1.8e2,1.7e-1,6,1.6e3]\n",
    "    labels = [\"CONSTANT\",\"AMPLITUDE\",\"TAU FAST\",\"TAU SLOW\"]\n",
    "    try:\n",
    "        popt, pcov = curve_fit(scint_profile,16*np.arange(len(ave_wvf)),ave_wvf,p0=initial)\n",
    "        perr = np.sqrt(np.diag(pcov))\n",
    "    except RuntimeError:\n",
    "        print(\"ERROR: Fit failed for \" + data[\"LABEL\"])\n",
    "        popt = initial\n",
    "        perr = np.zeros(len(initial))\n",
    "    # Print the fit results\n",
    "    ave_wvfs.append(scint_profile(16*np.arange(len(ave_wvf)),*popt))\n",
    "    print(\"\\n----------- FIT VALUES \" + data[\"LABEL\"]+ \" ------------\")\n",
    "    for i in range(len(initial)):\n",
    "        print(\"%s:\\t%.2E\\t%.2E\"%(labels[i], popt[i], perr[i]))\n",
    "    print(\"-----------------------------------------\")\n",
    "    print(len(ave_wvf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataframe for the plot\n",
    "wvfs  = np.concatenate([ave_wvfs[0],ave_wvfs[1],ave_wvfs[2],ave_wvfs[3]])\n",
    "wvfs_x  = np.concatenate([16*np.arange(len(ave_wvf)),16*np.arange(len(ave_wvf)),16*np.arange(len(ave_wvf)),16*np.arange(len(ave_wvf))])\n",
    "fit_label  = np.concatenate([[\"WVF\"]*len(ave_wvf),[\"FIT\"]*len(ave_wvf),[\"WVF\"]*len(ave_wvf),[\"FIT\"]*len(ave_wvf)])\n",
    "filter_label  = np.concatenate([[data2[\"LABEL\"]]*len(ave_wvf),[data2[\"LABEL\"]]*len(ave_wvf),[data3[\"LABEL\"]]*len(ave_wvf),[data3[\"LABEL\"]]*len(ave_wvf)])\n",
    "\n",
    "fit_df = pd.DataFrame({\"WVF\":wvfs,\"TIME in [ns]\":wvfs_x,\"FILTER\":filter_label,\"FIT\":fit_label})\n",
    "\n",
    "# Plot the results\n",
    "fig = px.line(data_frame=fit_df,x=\"TIME in [ns]\",y=\"WVF\",color=\"FIT\",facet_col=\"FILTER\",log_y=True,color_discrete_map=color_map)\n",
    "fig = format_coustom_plotly(fig,tickformat=(\",.2s\",\".2s\"),figsize=(None,600),fontsize=18,ranges=(None,None),facet_titles=[\"GAUSS\",\"WIENER\"])\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
